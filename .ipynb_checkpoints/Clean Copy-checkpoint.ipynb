{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d33bc10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools as ft\n",
    "#remove repeats\n",
    "from datetime import date,datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "798d9201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_reservations(df):\n",
    "    try:\n",
    "        Fab300_raw_reservations = df.copy()\n",
    "        SortedRows = Fab300_raw_reservations.sort_values([\"EVENT_ROW_ID\"])\n",
    "\n",
    "        index = range(1,len(SortedRows)+1)\n",
    "        IndexShift_1 = [i-1 if i%2 != 0 else np.nan for i in index]\n",
    "        IndexShift_2 = [i-1 if i%2 == 0 else np.nan for i in index]\n",
    "\n",
    "        SortedRows[\"Index\"] = index\n",
    "        SortedRows[\"IndexShift_1\"] = IndexShift_1\n",
    "        SortedRows[\"IndexShift_2\"] = IndexShift_2\n",
    "        SortedRows[\"IndexShift_1_1\"] = SortedRows[\"IndexShift_1\"].fillna(method='bfill')\n",
    "        SortedRows[\"IndexShift_2_1\"] = SortedRows[\"IndexShift_2\"].fillna(method='bfill')\n",
    "        SortedRows = SortedRows.drop(columns=['IndexShift_1', 'IndexShift_2'])\n",
    "        SortedRows = SortedRows.rename(columns={\"IndexShift_1_1\":\"IndexShift_1\",\"IndexShift_2_1\":\"IndexShift_2\"})\n",
    "        FilledUp2 = SortedRows.copy()\n",
    "\n",
    "        UnpivotedOnlySelectedColumns = pd.melt(FilledUp2, id_vars=['FO_ROW_ID','Index','IndexShift_1','IndexShift_2'], \n",
    "                    value_vars=[\"ResWBS\", \"ResTk\", \"DATE_TIME_STAMP\", \"USER_ID\", \"EVENT_ROW_ID\"])\n",
    "\n",
    "        UnpivotedOnlySelectedColumns[\"ResProperty_1\"] = np.where(UnpivotedOnlySelectedColumns['Index']==UnpivotedOnlySelectedColumns['IndexShift_1'], UnpivotedOnlySelectedColumns['variable'] + \"_Start\", UnpivotedOnlySelectedColumns['variable'] + \"_End\")\n",
    "        UnpivotedOnlySelectedColumns[\"ResProperty_2\"] = np.where(UnpivotedOnlySelectedColumns['Index']==UnpivotedOnlySelectedColumns['IndexShift_2'], UnpivotedOnlySelectedColumns['variable'] + \"_Start\", UnpivotedOnlySelectedColumns['variable'] + \"_End\")\n",
    "\n",
    "        AddedCustom4 = UnpivotedOnlySelectedColumns.copy()\n",
    "        RemovedColumns1 = AddedCustom4.drop(columns=[\"Index\", \"IndexShift_2\", \"variable\", \"ResProperty_2\"])\n",
    "\n",
    "        PivotedColumn1 = RemovedColumns1.pivot(index=['FO_ROW_ID','IndexShift_1'],columns='ResProperty_1',values='value').reset_index()\n",
    "\n",
    "        if \"ResWBS_Start\" in PivotedColumn1.columns:\n",
    "            FilteredRows01 = PivotedColumn1[(PivotedColumn1[\"ResWBS_Start\"].notnull() & PivotedColumn1['ResWBS_Start'].str.len() > 0)]\n",
    "        else:\n",
    "            #empty dataframe\n",
    "            FilteredRows01 = pd.DataFrame(columns=PivotedColumn1.columns)\n",
    "            \n",
    "        \n",
    "        RemovedColumns2 = AddedCustom4.drop(columns=[\"Index\", \"IndexShift_1\", \"variable\", \"ResProperty_1\"])\n",
    "        PivotedColumn2 = RemovedColumns2.pivot(index=['FO_ROW_ID','IndexShift_2'],columns='ResProperty_2',values='value').reset_index()\n",
    "\n",
    "        FilteredRows02 = PivotedColumn2[(PivotedColumn2[\"ResWBS_Start\"].notnull() & PivotedColumn2['ResWBS_Start'].str.len() > 0)]\n",
    "        \n",
    "        if \"ResWBS_Start\" in PivotedColumn2.columns:\n",
    "            FilteredRows02 = PivotedColumn2[(PivotedColumn2[\"ResWBS_Start\"].notnull() & PivotedColumn2['ResWBS_Start'].str.len() > 0)]\n",
    "        else:\n",
    "            #empty dataframe\n",
    "            FilteredRows02 = pd.DataFrame(columns=PivotedColumn2.columns)\n",
    "        \n",
    "        columns = [\n",
    "            'FO_ROW_ID', \n",
    "            'DATE_TIME_STAMP_End',\n",
    "            'DATE_TIME_STAMP_Start', \n",
    "            'EVENT_ROW_ID_End', \n",
    "            'EVENT_ROW_ID_Start',\n",
    "            'ResTk_End', \n",
    "            'ResTk_Start', \n",
    "            'ResWBS_End', \n",
    "            'ResWBS_Start', \n",
    "            'USER_ID_End',\n",
    "            'USER_ID_Start'\n",
    "        ]\n",
    "            \n",
    "            \n",
    "        if FilteredRows01.shape[0] == 0:\n",
    "            combined = FilteredRows02[columns]\n",
    "        elif FilteredRows02.shape[0] == 0:\n",
    "            combined = FilteredRows01[columns]\n",
    "        else:\n",
    "            FilteredRows01 = FilteredRows01[columns]\n",
    "            FilteredRows02 = FilteredRows02[columns]\n",
    "        \n",
    "        combined = pd.concat([FilteredRows01,FilteredRows02])\n",
    "\n",
    "        combined = combined.rename(\n",
    "            columns=\n",
    "            {\n",
    "                \"ResTk_Start\":\"ResTk\",\n",
    "                \"ResWBS_Start\":\"WBS\",\n",
    "                \"EVENT_ROW_ID_Start\": \"EVENT_ROW_ID_Begin\",\n",
    "                \"DATE_TIME_STAMP_Start\": \"DATE_TIME_STAMP_Begin\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        columns = [\n",
    "            \"FO_ROW_ID\",\n",
    "            \"ResTk\", \n",
    "            \"WBS\", \n",
    "            \"EVENT_ROW_ID_Begin\", \n",
    "            \"EVENT_ROW_ID_End\", \n",
    "            \"DATE_TIME_STAMP_Begin\", \n",
    "            \"DATE_TIME_STAMP_End\", \n",
    "            \"USER_ID_Start\", \n",
    "            \"USER_ID_End\"\n",
    "        ]\n",
    "        Tools_with_resersvations  = combined#[columns]\n",
    "\n",
    "        final = combined[columns]\n",
    "        return final\n",
    "    except:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def processFab300RawReservations(df):\n",
    "    columns = [\n",
    "        \"FO_ROW_ID\",\n",
    "        \"DATE_TIME_STAMP_Begin\",\n",
    "        \"DATE_TIME_STAMP_End\",\n",
    "        'EVENT_ROW_ID_Begin', \n",
    "        'EVENT_ROW_ID_End',\n",
    "        'ResTk',\n",
    "        'USER_ID_Start',\n",
    "        'USER_ID_End',\n",
    "        'WBS'\n",
    "    ]\n",
    "\n",
    "    for_row_ids = df[\"FO_ROW_ID\"].unique()\n",
    "\n",
    "    Tools_with_reservations = pd.DataFrame(columns=columns)\n",
    "    for row_id in for_row_ids:\n",
    "        grpdata = df[df[\"FO_ROW_ID\"] == row_id]\n",
    "\n",
    "        df_reserv = identify_reservations(grpdata)\n",
    "        if df.shape[0] > 0:\n",
    "            Tools_with_reservations = pd.concat([Tools_with_reservations,df_reserv])\n",
    "\n",
    "\n",
    "    return Tools_with_reservations\n",
    "\n",
    "\n",
    "def FAB300_with_tool_names(Tools_with_reservations,Tools_Parents):\n",
    "    Expanded_Tools_parents = pd.merge(\n",
    "        Tools_with_reservations, \n",
    "        Tools_Parents, \n",
    "        left_on=[\"FO_ROW_ID\"], \n",
    "        right_on=[\"ROW_ID\"], \n",
    "        how=\"left\",\n",
    "        suffixes=[\"\",\"_y\"]\n",
    "    )\n",
    "    Expanded_Tools_parents = Expanded_Tools_parents.rename(\n",
    "        columns={\n",
    "            \"ENT_NAME\":\"Tool\",\n",
    "            \"USER_ID_Start\":\"USER_ID_Begin\",\n",
    "            \"USER_ID_End\":\"USER_ID_End\"\n",
    "        }\n",
    "    )\n",
    "    Expanded_Tools_parents_filteredRows = Expanded_Tools_parents[\n",
    "        Expanded_Tools_parents[\"USER_ID_Begin\"] == Expanded_Tools_parents[\"USER_ID_End\"]\n",
    "    ]\n",
    "    Expanded_Tools_parents_filteredRows = Expanded_Tools_parents_filteredRows.rename(\n",
    "        columns={\n",
    "            \"USER_ID_Begin\":\"User_id\",\n",
    "            \"DATE_TIME_STAMP_Begin\":\"Begin\",\n",
    "            \"DATE_TIME_STAMP_End\":\"End\"\n",
    "        }\n",
    "    )\n",
    "    Expanded_Tools_parents_filteredRows = Expanded_Tools_parents_filteredRows.sort_values([\"FO_ROW_ID\",\"EVENT_ROW_ID_Begin\"])\n",
    "    Fab300_Res_id = range(0,len(Expanded_Tools_parents_filteredRows))\n",
    "    Expanded_Tools_parents_filteredRows[\"Fab300_Res_id\"] = Fab300_Res_id\n",
    "    Expanded_Tools_parents_filteredRows = Expanded_Tools_parents_filteredRows[\n",
    "        (Expanded_Tools_parents_filteredRows[\"Tool\"].notnull())\n",
    "        & (Expanded_Tools_parents_filteredRows['Tool'].str.len() > 0)\n",
    "    ]\n",
    "    columns = [\n",
    "        \"FO_ROW_ID\",\n",
    "        \"EVENT_ROW_ID_Begin\",\n",
    "        \"Begin\",\n",
    "        \"End\",\n",
    "        \"Fab300_Res_id\",\n",
    "        \"FACILITY\",\n",
    "        \"ResTk\",\n",
    "        \"Tool\",\n",
    "        \"User_id\",\n",
    "        \"WBS\"\n",
    "    ]\n",
    "    Expanded_Tools_parents_filteredRows[columns]\n",
    "    FAB300_with_tool_names = Expanded_Tools_parents_filteredRows[columns]\n",
    "\n",
    "    #Sample for FO_ROW_ID == 76\n",
    "    return FAB300_with_tool_names\n",
    "\n",
    "\n",
    "#IIO_raw_reservations\n",
    "def IIO_without_modules(df):\n",
    "    df = df.reset_index()\n",
    "    df = df.sort_values([\"WBS\",\"Tool\",\"FACILITY\",\"Module\",\"Begin\"])\n",
    "    df[\"End_Down\"] = df[\"End\"].shift(1)\n",
    "    df[\"Adjacent_Down\"] = np.where(df['Begin']==df['End_Down'], True, False)\n",
    "    df[\"IndexCopy\"] = np.where(df[\"Adjacent_Down\"] == True,np.nan,df[\"index\"])\n",
    "    df[\"IndexCopy2\"] = df[\"IndexCopy\"].fillna(method='ffill')\n",
    "    df[\"Module\"] = df[\"Module\"].fillna(\"\")\n",
    "    df[\"Description\"] = df[\"Description\"].fillna(\"\")\n",
    "    df = df[['WBS','FACILITY', 'Module','Tool','Begin', 'Description', 'End', 'User_id','IndexCopy2','End_Down']]\n",
    "\n",
    "\n",
    "    params = {\n",
    "        'Begin': 'min',\n",
    "        'End': 'max',\n",
    "        'Description': lambda x: ';'.join(sorted(pd.Series.unique(x))),\n",
    "        'User_id': lambda x: ';'.join(sorted(pd.Series.unique(x)))\n",
    "    }\n",
    "    sub = df[[\"WBS\",\"Tool\",\"FACILITY\",\"Module\",\"Begin\",\"End\",\"Description\",'User_id','IndexCopy2']]\n",
    "    GroupedRows1 = sub.groupby([\"WBS\",\"Tool\",\"FACILITY\",\"Module\",'IndexCopy2']).agg(params).reset_index()\n",
    "\n",
    "    params = {\n",
    "        'Module': lambda x: ';'.join(sorted(pd.Series.unique(x))),\n",
    "        'Description': 'first',\n",
    "        'User_id': 'first'\n",
    "    }\n",
    "    \n",
    "\n",
    "    GroupedRows1 = GroupedRows1.groupby([\"WBS\",\"Tool\",\"FACILITY\",\"Begin\", \"End\"]).agg(params).reset_index()\n",
    "    GroupedRows1 = GroupedRows1.sort_values([\"FACILITY\", \"Tool\", \"WBS\", \"Begin\", \"End\"])\n",
    "\n",
    "    Index = range(0,len(GroupedRows1))\n",
    "    GroupedRows1[\"IIO_Res_id\"] = Index\n",
    "    \n",
    "    GroupedRows1 = GroupedRows1.rename(\n",
    "        columns={\n",
    "            \"Module\":\"Modules\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    IIO_without_modules = GroupedRows1.copy()\n",
    "    return IIO_without_modules\n",
    "\n",
    "\n",
    "def Fab300_iio_merger(df,verbose=False):\n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
    "    df = df.sort_values([\"WBS\",\"FACILITY\",'Tool',\"DateTime\",\"FAB300_BeginEnd\"])\n",
    "    \n",
    "    df[\"Fab300_Res_id_UP\"] = df[\"Fab300_Res_id\"].fillna(method='bfill')\n",
    "    df[\"Fab300_Res_id_DOWN\"] = df[\"Fab300_Res_id\"].fillna(method='ffill')\n",
    "    df[\"IIO_Res_id_UP\"] = df[\"IIO_Res_id\"].fillna(method='bfill')\n",
    "    df[\"IIO_Res_id_DOWN\"] = df[\"IIO_Res_id\"].fillna(method='ffill')\n",
    "    \n",
    "    if verbose:\n",
    "        print(df.shape)\n",
    "        \n",
    "    fab_iio_Filtered_Rows = df[\n",
    "        (df[\"Fab300_Res_id_UP\"] == df[\"Fab300_Res_id_DOWN\"])\n",
    "        & (df[\"IIO_Res_id_UP\"] == df[\"IIO_Res_id_DOWN\"])\n",
    "        & (df[\"Fab300_Res_id_UP\"].notnull())\n",
    "        & (df[\"IIO_Res_id_UP\"].notnull())\n",
    "    ] \n",
    "    if verbose:\n",
    "        print(fab_iio_Filtered_Rows.shape)\n",
    "        \n",
    "    Removed_Other_Columns = fab_iio_Filtered_Rows[[\"Fab300_Res_id_UP\", \"IIO_Res_id_UP\"]]\n",
    "    Removed_Duplicates = Removed_Other_Columns.drop_duplicates()\n",
    "    Renamed_Columns = Removed_Duplicates.rename(\n",
    "        columns = {\n",
    "            \"Fab300_Res_id_UP\":\"Fab300_Res_id\",\n",
    "            \"IIO_Res_id_UP\":\"IIO_Res_id\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    index = range(0,len(Renamed_Columns))\n",
    "    Renamed_Columns[\"Index\"] = index\n",
    "    Added_Index = Renamed_Columns.copy()\n",
    "    State_DOWN_Remove = Added_Index.copy()\n",
    "    State_DOWN_Remove.loc[-1] = [np.nan,np.nan,-1]  # adding a row\n",
    "    State_DOWN_Insert = State_DOWN_Remove.copy()\n",
    "    State_DOWN_Insert = State_DOWN_Insert.sort_values([\"Index\"])\n",
    "    index2 = range(0,len(State_DOWN_Insert))\n",
    "    State_DOWN_Insert[\"Index2\"] = index2\n",
    "\n",
    "    State_DOWN_Add_Index = State_DOWN_Insert.copy()\n",
    "    State_DOWN_Rename = State_DOWN_Add_Index.rename(\n",
    "        columns = {\n",
    "            \"Fab300_Res_id\":\"Fab300_Res_id_DOWN\",\n",
    "            \"IIO_Res_id\":\"IIO_Res_id_DOWN\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    With_DOWN = Added_Index.merge(\n",
    "        State_DOWN_Rename, \n",
    "        left_on=[\"Index\"],\n",
    "        right_on=[\"Index2\"],\n",
    "        suffixes=[\"\",\"_y\"],\n",
    "        how = 'left'\n",
    "    )\n",
    "\n",
    "    With_DOWN[\"Index3\"] = np.where(\n",
    "        (With_DOWN['Fab300_Res_id']==With_DOWN['Fab300_Res_id_DOWN'])\n",
    "        | (With_DOWN['IIO_Res_id']==With_DOWN['IIO_Res_id_DOWN']), \n",
    "        np.nan,\n",
    "         With_DOWN['Index']\n",
    "    )\n",
    "\n",
    "\n",
    "    Replaced_Value = With_DOWN.copy()\n",
    "    Replaced_Value[\"Index4\"] = Replaced_Value[\"Index3\"].fillna(method='ffill')\n",
    "    Replaced_Value = Replaced_Value.drop(columns=[\"Fab300_Res_id_DOWN\", \"IIO_Res_id_DOWN\"])\n",
    "    Renamed_Columns1 = Replaced_Value.rename(\n",
    "    columns={\n",
    "        \"Index4\":\"Cluster\"\n",
    "    })\n",
    "\n",
    "\n",
    "    Merged_queries = Renamed_Columns1.merge(\n",
    "        Source_fab, \n",
    "        left_on=[\"Fab300_Res_id\"],\n",
    "        right_on=[\"Fab300_Res_id\"],\n",
    "        suffixes=[\"\",\"_y\"],\n",
    "        how = 'left'\n",
    "    )\n",
    "    Expanded_Fab300_with_tool_names = Merged_queries.rename(\n",
    "    columns ={\n",
    "        \"Begin\": \"Fab300_Begin\", \n",
    "        \"End\": \"Fab300_End\", \n",
    "        \"User_id\": \"Fab300_User_id\"\n",
    "    })\n",
    "    Merged_queries_1 = Expanded_Fab300_with_tool_names.merge(\n",
    "        Source_iio, \n",
    "        left_on=[\"IIO_Res_id\"],\n",
    "        right_on=[\"IIO_Res_id\"],\n",
    "        suffixes=[\"\",\"_y\"],\n",
    "        how = 'left'\n",
    "    )\n",
    "    Expanded_IIO_without_modules = Merged_queries_1.rename(\n",
    "    columns ={\n",
    "        \"Begin\": \"IIO_Begin\", \n",
    "        \"End\": \"IIO_End\", \n",
    "        \"Modules\": \"Modules\",\n",
    "        \"User_id\": \"IIO_User_id\",\n",
    "        \"Description\": \"Description\"\n",
    "    })\n",
    "    Expanded_IIO_without_modules = Expanded_IIO_without_modules.drop(\n",
    "        columns=[\"FACILITY_y\",\"Tool_y\",\"WBS_y\",'Index', 'Index_y', 'Index2', 'Index3']\n",
    "    )\n",
    "    \n",
    "    return Expanded_IIO_without_modules\n",
    "\n",
    "\n",
    "def Final_Fab300_IIO_reservations(IIO_without_modules,Fab300withtoolnames,Fab300_IIO_overlaps_ids):\n",
    "    Fab300_IIO_overlaps_ids[\"Fab300_Begin\"] = pd.to_datetime(Fab300_IIO_overlaps_ids[\"Fab300_Begin\"],format=\"%Y-%m-%d %H:%M\")\n",
    "    Fab300_IIO_overlaps_ids[\"Fab300_End\"] = pd.to_datetime(Fab300_IIO_overlaps_ids[\"Fab300_End\"],format=\"%Y-%m-%d %H:%M\")\n",
    "    Fab300_IIO_overlaps_ids[\"IIO_Begin\"] = pd.to_datetime(Fab300_IIO_overlaps_ids[\"IIO_Begin\"],format=\"%Y-%m-%d %H:%M\")\n",
    "    Fab300_IIO_overlaps_ids[\"IIO_End\"] = pd.to_datetime(Fab300_IIO_overlaps_ids[\"IIO_End\"],format=\"%Y-%m-%d %H:%M\")\n",
    "    \n",
    "    AddedCustom = Fab300_IIO_overlaps_ids.copy()\n",
    "\n",
    "    AddedCustom['Modules'] = AddedCustom['Modules'].fillna('')\n",
    "    AddedCustom[\"Fab300_Duration\"] = (AddedCustom[\"Fab300_End\"] - AddedCustom[\"Fab300_Begin\"])/np.timedelta64(1, 'h')\n",
    "    AddedCustom1 = AddedCustom.copy()\n",
    "    AddedCustom1[\"IIO_Duration\"] = (AddedCustom1[\"IIO_End\"] - AddedCustom1[\"IIO_Begin\"])/np.timedelta64(1, 'h')\n",
    "    params = {\n",
    "        'Fab300_Begin': 'min',\n",
    "        'IIO_Begin': 'min',\n",
    "        'Fab300_End': 'max',\n",
    "        'IIO_End': 'max',\n",
    "        'Fab300_Res_id': 'count',\n",
    "        'Description': lambda x: ';'.join(sorted(pd.Series.unique(x))),\n",
    "        'IIO_User_id': lambda x: ';'.join(sorted(pd.Series.unique(x))),\n",
    "        'Fab300_User_id': lambda x: ';'.join(sorted(pd.Series.unique(x))),\n",
    "        'Modules': lambda x: ';'.join(sorted(pd.Series.unique(x)))\n",
    "    }\n",
    "    sub = AddedCustom1[\n",
    "        [\n",
    "            \"FACILITY\", \n",
    "            \"Tool\", \n",
    "            \"WBS\", \n",
    "            \"Cluster\",\n",
    "            \"Fab300_Begin\",\n",
    "            \"IIO_Begin\",\n",
    "            'Fab300_End',\n",
    "            'IIO_End',\n",
    "            'Fab300_Res_id',\n",
    "            'IIO_Res_id',\n",
    "            'Description',\n",
    "            'IIO_User_id',\n",
    "            'Fab300_User_id',\n",
    "            'Modules'\n",
    "        ]\n",
    "    ]\n",
    "    GroupedRows1 = sub.groupby([\"FACILITY\", \"Tool\", \"WBS\", \"Cluster\"]).agg(params).reset_index()\n",
    "    GroupedRows1[\"Begin\"] = np.where(GroupedRows1['Fab300_Begin']>GroupedRows1['IIO_Begin'], GroupedRows1['IIO_Begin'], GroupedRows1['Fab300_Begin'])\n",
    "    GroupedRows1[\"End\"]  = np.where(GroupedRows1['Fab300_End']>GroupedRows1['IIO_End'], GroupedRows1['Fab300_End'], GroupedRows1['IIO_End'])\n",
    "    GroupedRows1 = GroupedRows1.rename(\n",
    "    columns={\n",
    "        \"Fab300_Res_id\": \"Cnt\"\n",
    "    }).drop(columns=['Fab300_Begin','Fab300_End','IIO_Begin','IIO_End'])\n",
    "\n",
    "\n",
    "    Duration_FAB = AddedCustom1[\n",
    "        [\n",
    "            \"FACILITY\", \n",
    "            \"Tool\", \n",
    "            \"WBS\", \n",
    "            \"Cluster\",\n",
    "            \"Fab300_Res_id\",\n",
    "            'Fab300_Duration'\n",
    "        ]\n",
    "    ].drop_duplicates().reset_index()\n",
    "\n",
    "    Duration_IIO = AddedCustom1[\n",
    "        [\n",
    "            \"FACILITY\", \n",
    "            \"Tool\", \n",
    "            \"WBS\", \n",
    "            \"Cluster\",\n",
    "            \"IIO_Res_id\",\n",
    "            'IIO_Duration'\n",
    "        ]\n",
    "    ].drop_duplicates().reset_index()\n",
    "\n",
    "    GroupedRows1_FAB = Duration_FAB.groupby([\"FACILITY\", \"Tool\", \"WBS\", \"Cluster\"]).sum().reset_index()\n",
    "    GroupedRows1_IIO = Duration_IIO.groupby([\"FACILITY\", \"Tool\", \"WBS\", \"Cluster\"]).sum().reset_index()\n",
    "\n",
    "\n",
    "    GroupedRows = pd.concat(\n",
    "        objs=(iDF.set_index([\"FACILITY\", \"Tool\", \"WBS\", \"Cluster\"]) for iDF in (GroupedRows1, GroupedRows1_FAB, GroupedRows1_IIO)),\n",
    "        axis=1, \n",
    "        join='inner'\n",
    "    ).reset_index()\n",
    "    GroupedRows['FAB_IIO_Ratio'] = GroupedRows[\"Fab300_Duration\"] / GroupedRows[\"IIO_Duration\"]\n",
    "\n",
    "    GroupedRows = GroupedRows[\n",
    "        [\n",
    "            'FACILITY', \n",
    "            'Tool', \n",
    "            'WBS', \n",
    "            'Cluster', \n",
    "            'Cnt', \n",
    "            'Description',\n",
    "            'Begin', \n",
    "            'End',\n",
    "            'IIO_User_id', \n",
    "            'Fab300_User_id', \n",
    "            'Modules',\n",
    "            'Fab300_Duration', \n",
    "            'IIO_Duration', \n",
    "            'FAB_IIO_Ratio'\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    FilteredRows = GroupedRows[\n",
    "        (GroupedRows[\"FAB_IIO_Ratio\"] < 3.0)\n",
    "        & (GroupedRows[\"Cnt\"] <= 4)\n",
    "    ]\n",
    "\n",
    "    Fab300_IIO_valid_combos = FilteredRows.drop(columns = [\"Cnt\"])\n",
    "\n",
    "    outer = Fab300_IIO_overlaps_ids.merge(\n",
    "        Fab300_IIO_valid_combos, \n",
    "        how='outer',\n",
    "        left_on = [\"FACILITY\", \"Tool\", \"WBS\", \"Cluster\"],\n",
    "        right_on = [\"FACILITY\", \"Tool\", \"WBS\", \"Cluster\"],\n",
    "        indicator=True\n",
    "    )\n",
    "    Fab300_IIO_bad_combos = outer[(outer._merge=='left_only')].drop('_merge', axis=1)\n",
    "\n",
    "\n",
    "    IIO_ids_from_bad_combos = Fab300_IIO_bad_combos[[\"IIO_Res_id\"]]\n",
    "    RemovedDuplicates = IIO_ids_from_bad_combos.drop_duplicates()\n",
    "\n",
    "    MergedQueries = RemovedDuplicates.merge(\n",
    "        IIO_without_modules, \n",
    "        how='inner',\n",
    "        left_on = [\"IIO_Res_id\"],\n",
    "        right_on = [\"IIO_Res_id\"],\n",
    "        indicator=True\n",
    "    )\n",
    "    RemovedColumns1 = MergedQueries.drop(columns=[\"IIO_Res_id\"])\n",
    "    IIO_from_bad_combos = RemovedColumns1.rename(\n",
    "    columns = {\n",
    "        'User_id':'IIO_User_id'\n",
    "    }).drop(columns=[\"_merge\"])\n",
    "\n",
    "    outer_IIO_from_bad_combos = IIO_without_modules.merge(\n",
    "        Fab300_IIO_overlaps_ids, \n",
    "        how='outer',\n",
    "        left_on = [\"IIO_Res_id\"],\n",
    "        right_on = [\"IIO_Res_id\"],\n",
    "        indicator=True\n",
    "    )\n",
    "    Pure_IIO_Join = outer_IIO_from_bad_combos[(outer_IIO_from_bad_combos._merge=='left_only')].drop('_merge', axis=1)\n",
    "    Pure_IIO = Pure_IIO_Join[\n",
    "        [\n",
    "            'Begin', \n",
    "            'Description_x', \n",
    "            'End', \n",
    "            'FACILITY_x', \n",
    "            'IIO_Res_id',\n",
    "            'Modules_x', \n",
    "            'Tool_x', \n",
    "            'User_id', \n",
    "            'WBS_x'\n",
    "        ]\n",
    "    ]\n",
    "    RenamedColumns = Pure_IIO.rename(\n",
    "        columns = {\n",
    "            'User_id':'IIO_User_id',\n",
    "            'Description_x': 'Description',\n",
    "            'FACILITY_x': 'FACILITY',\n",
    "            'Modules_x': 'Modules',\n",
    "            'Tool_x': 'Tool',\n",
    "            'WBS_x': 'WBS'\n",
    "        }\n",
    "    )\n",
    "    AppendedQuery = pd.concat([RenamedColumns,IIO_from_bad_combos]).drop(columns=['IIO_Res_id'])\n",
    "    AppendedQuery[\"Begin\"] = pd.to_datetime(AppendedQuery[\"Begin\"],format=\"%Y-%m-%d %H:%M\")\n",
    "    AppendedQuery[\"End\"] = pd.to_datetime(AppendedQuery[\"End\"],format=\"%Y-%m-%d %H:%M\")\n",
    "    AppendedQuery[\"IIO_Duration\"] = (AppendedQuery[\"End\"] - AppendedQuery[\"Begin\"])/np.timedelta64(1, 'h')\n",
    "    AddedCustom2 = AppendedQuery.copy()\n",
    "    AppendedQuery2 = pd.concat([Fab300_IIO_valid_combos,AddedCustom2])\n",
    "\n",
    "    outer_Fab300withtoolnames = Fab300withtoolnames.merge(\n",
    "        Fab300_IIO_overlaps_ids, \n",
    "        how='outer',\n",
    "        left_on = [\"Fab300_Res_id\"],\n",
    "        right_on = [\"Fab300_Res_id\"],\n",
    "        indicator=True\n",
    "    )\n",
    "\n",
    "    Pure_Fab300_Join = outer_Fab300withtoolnames[(outer_Fab300withtoolnames._merge=='left_only')].drop('_merge', axis=1)\n",
    "    Pure_Fab300 = Pure_Fab300_Join[\n",
    "        [\n",
    "            'Begin', \n",
    "            'End', \n",
    "            'Fab300_Res_id', \n",
    "            'FACILITY_x', \n",
    "            'Tool_x',\n",
    "            'User_id',\n",
    "            'WBS_x'\n",
    "        ]\n",
    "    ].drop(columns=['Fab300_Res_id']).rename(\n",
    "    columns={\n",
    "            'FACILITY_x': 'FACILITY',\n",
    "            'Tool_x': 'Tool',\n",
    "            'User_id': 'Fab300_User_id',\n",
    "            'WBS_x': 'WBS'\n",
    "    })\n",
    "    RenamedColumns1 = Pure_Fab300.copy()\n",
    "\n",
    "    RenamedColumns1[\"Begin\"] = pd.to_datetime(RenamedColumns1[\"Begin\"],format=\"%Y-%m-%d %H:%M\")\n",
    "    RenamedColumns1[\"End\"] = pd.to_datetime(RenamedColumns1[\"End\"],format=\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "    RenamedColumns1[\"Fab300_Duration\"] = (RenamedColumns1[\"End\"] - RenamedColumns1[\"Begin\"])/np.timedelta64(1, 'h')\n",
    "    AddedCustom3 = RenamedColumns1.copy()\n",
    "\n",
    "    AppendedQuery3 = pd.concat([AppendedQuery2,AddedCustom3]).drop(columns=['FAB_IIO_Ratio'])\n",
    "    return AppendedQuery3\n",
    "\n",
    "\n",
    "def GetOverlapIndicator(row):\n",
    "    if (row[\"Scanners.Begin\"] is pd.NaT):\n",
    "        return \"No overlap\"\n",
    "    else:\n",
    "        if row[\"Scanners.Begin\"] < row[\"End\"] and row[\"Scanners.End\"] > row[\"Begin\"]:\n",
    "            if row[\"Begin\"] > row[\"Scanners.Begin\"] and row[\"End\"] < row[\"Scanners.End\"]:\n",
    "                return \"Useful overlap\"\n",
    "            else:\n",
    "                return \"Ignore overlap\"\n",
    "        else:\n",
    "            return \"No overlap\"\n",
    "\n",
    "\n",
    "def CheckForOverlaps(df):\n",
    "    Removed_Duplicates = df[\"Overlap\"].unique()\n",
    "    nb_of_rows = Removed_Duplicates.shape[0]\n",
    "    FirstValue = Removed_Duplicates[0]\n",
    "\n",
    "    if (nb_of_rows == 1) and (FirstValue == \"No overlap\"):\n",
    "        return True \n",
    "\n",
    "    return False\n",
    "\n",
    "def GetMinDate(row,col1, col2):\n",
    "    if (row[col1] is pd.NaT and row[col2] is not pd.NaT):\n",
    "        return row[col2]\n",
    "    elif (row[col1] is not pd.NaT and row[col2] is pd.NaT):\n",
    "        return row[col1]\n",
    "    else:\n",
    "        if row[col1] < row[col2]:\n",
    "            return row[col1]\n",
    "        else:\n",
    "            return row[col2]\n",
    "        \n",
    "def GetMaxDate(row,col1, col2):\n",
    "    if (row[col1] is pd.NaT and row[col2] is not pd.NaT):\n",
    "        return row[col2]\n",
    "    elif (row[col1] is not pd.NaT and row[col2] is pd.NaT):\n",
    "        return row[col1]\n",
    "    else:\n",
    "        if row[col1] < row[col2]:\n",
    "            return row[col2]\n",
    "        else:\n",
    "            return row[col1]\n",
    "\n",
    "\n",
    "def Final_Fab300_IIO_Reservations_clustered(df):\n",
    "    MergedQueries = df.merge(\n",
    "        LithoClusters, \n",
    "        how='left',\n",
    "        left_on = [\"Tool\"],\n",
    "        right_on = [\"ToolName\"]\n",
    "    )\n",
    "\n",
    "    print(\"MergedQueries\", MergedQueries.shape)\n",
    "    MergedQueries = MergedQueries.drop(columns=[\"ToolName\"])\n",
    "\n",
    "    SC_TR_filt = MergedQueries[\n",
    "        (MergedQueries[\"LithoCluster\"].notnull())\n",
    "        & (MergedQueries[\"LithoCluster\"] != \"\")\n",
    "    ]\n",
    "\n",
    "    SC_filt = SC_TR_filt[\n",
    "        SC_TR_filt[\"Tool\"].str.startswith(\"SC\")\n",
    "    ]\n",
    "    SC_filt['Tool'] = SC_filt['Tool'].str.replace('SC','LithoCluster_')\n",
    "    SC_to_Cluster = SC_filt.copy()\n",
    "    SC_index = SC_to_Cluster.copy()\n",
    "\n",
    "\n",
    "    index = range(0,len(SC_index))\n",
    "    SC_index[\"id\"] = index\n",
    "\n",
    "\n",
    "    TR_filt = SC_TR_filt[\n",
    "        SC_TR_filt[\"Tool\"].str.startswith(\"TR\")\n",
    "    ]\n",
    "    TR_index = TR_filt.copy()\n",
    "    index2 = range(0,len(TR_index))\n",
    "    TR_index[\"id\"] = index2\n",
    "\n",
    "\n",
    "    SC_index_sub = SC_index[\n",
    "        [\n",
    "            \"LithoCluster\", \"WBS\",\"Begin\", \"End\", \"id\"\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    TR_SC_Merge = TR_index.merge(\n",
    "        SC_index_sub, \n",
    "        how='left',\n",
    "        left_on = [\"LithoCluster\", \"WBS\"],\n",
    "        right_on = [\"LithoCluster\", \"WBS\"]\n",
    "    )\n",
    "    TR_SC_Expand = TR_SC_Merge.rename(\n",
    "    columns = {\n",
    "        \"Begin_y\":\"Scanners.Begin\",\n",
    "        \"End_y\":\"Scanners.End\",\n",
    "        \"Begin_x\":\"Begin\",\n",
    "        \"End_x\":\"End\",\n",
    "        \"id_y\":\"Scanners.id\",\n",
    "        \"id_x\":\"id\",\n",
    "        \"Cluster_x\": \"Cluster\",\n",
    "        'Description_x':\"Description\",\n",
    "        'Fab300_Duration_x':\"Fab300_Duration\",\n",
    "        'Fab300_User_id_x':\"Fab300_User_id\", \n",
    "        'FACILITY_x':\"FACILITY\", \n",
    "        'IIO_Duration_x':\"IIO_Duration\", \n",
    "        'IIO_User_id_x':\"IIO_User_id\",\n",
    "        'Modules_x':\"Modules\", \n",
    "        'Tool_x':\"Tool\"\n",
    "        \n",
    "    })\n",
    "\n",
    "    TR_SC_ovl_info = TR_SC_Expand.copy()\n",
    "    TR_SC_ovl_info[\"Overlap\"]  = TR_SC_ovl_info.apply(lambda row: GetOverlapIndicator(row),axis=1)\n",
    "\n",
    "    collated = pd.DataFrame(columns=[\n",
    "        'Begin', \n",
    "        'Cluster', \n",
    "        'Description', \n",
    "        'End', \n",
    "        'Fab300_Duration',\n",
    "        'Fab300_User_id', \n",
    "        'FACILITY', \n",
    "        'IIO_Duration', \n",
    "        'IIO_User_id', \n",
    "        'Modules',\n",
    "        'Tool', \n",
    "        'WBS', \n",
    "        'LithoCluster', \n",
    "        'id', \n",
    "        'Scanners.Begin', \n",
    "        'Scanners.End',\n",
    "        'Scanners.id', \n",
    "        'Overlap',\n",
    "        'Independent'\n",
    "    ])\n",
    "\n",
    "\n",
    "    ids = TR_SC_ovl_info[\"id\"].unique()\n",
    "\n",
    "    for id in ids:\n",
    "        grp = TR_SC_ovl_info[TR_SC_ovl_info[\"id\"] == id]\n",
    "        grp[\"Independent\"] = CheckForOverlaps(grp)\n",
    "        \n",
    "        collated = pd.concat([collated,grp])\n",
    "\n",
    "    TR_pure = collated[collated[\"Independent\"] == True]\n",
    "    TR_pure = TR_pure[[\"id\"]]\n",
    "\n",
    "    TR_merge  = TR_pure.merge(\n",
    "        TR_index, \n",
    "        how='inner',\n",
    "        left_on = [\"id\"],\n",
    "        right_on = [\"id\"]\n",
    "    )\n",
    "    TR_rmv = TR_merge.drop(columns=[\"id\"])\n",
    "\n",
    "\n",
    "    SC_filt_2 = TR_SC_ovl_info[\n",
    "        (TR_SC_ovl_info[\"Overlap\"] != \"No overlap\")\n",
    "        & (TR_SC_ovl_info[\"Overlap\"] != \"Ignore overlap\")\n",
    "    ]\n",
    "    SC_TR_columns = SC_filt_2[[\"Cluster\", \"Begin\", \"End\", \"Scanners.id\"]]\n",
    "\n",
    "    SC_TR_columns2 = SC_TR_columns[\n",
    "        [\n",
    "            \"Scanners.id\",\n",
    "            \"Begin\", \n",
    "            \"End\", \n",
    "            \"Cluster\"\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    SC_pure = SC_index.merge(\n",
    "        SC_TR_columns2, \n",
    "        how='left',\n",
    "        left_on = [\"id\"],\n",
    "        right_on = [\"Scanners.id\"]\n",
    "    )\n",
    "    SC_rename = SC_pure.rename(\n",
    "    columns={\n",
    "        \"Begin_y\": \"TR_Begin\", \n",
    "        \"End_y\": \"TR_End\", \n",
    "        \"Begin_x\": \"SC_Begin\", \n",
    "        \"End_x\": \"SC_End\", \n",
    "        \"Cluster_x\": \"Cluster\",\n",
    "        \"Cluster_y\": \"TR_Cluster\",\n",
    "        \n",
    "    })\n",
    "    SC_rename[\"Begin\"] = SC_rename.apply(lambda row: GetMinDate(row,\"SC_Begin\",\"TR_Begin\"),axis=1)\n",
    "    SC_rename[\"End\"] = SC_rename.apply(lambda row: GetMaxDate(row,\"SC_End\",\"TR_End\"),axis=1)\n",
    "    SC_final = SC_rename.drop(columns=[\"SC_Begin\", \"SC_End\", \"id\", \"TR_Begin\", \"TR_End\"])\n",
    "    NoClusters = MergedQueries[MergedQueries[\"LithoCluster\"].isna()]\n",
    "\n",
    "    Everything = pd.concat([NoClusters, TR_rmv])\n",
    "    Everything = pd.concat([Everything,SC_final])\n",
    "    Everything.drop_duplicates(inplace=True)\n",
    "\n",
    "    return Everything\n",
    "\n",
    "\n",
    "def ReducedState(row):\n",
    "    if row[\"State\"] in [\"UP\",\"PARTLY_UP\",\"RESERVED\"]:\n",
    "        return \"UP\"\n",
    "    elif row[\"State\"] == \"SPC_TEST\":\n",
    "        return \"SPC\"\n",
    "    elif row[\"State\"] == \"OCAP\":\n",
    "        return \"OCAP\"\n",
    "    else:\n",
    "        return \"DOWN\"\n",
    "\n",
    "\n",
    "\n",
    "def Transform_states(df,fo_row_id):\n",
    "    df[\"ReducedState\"] = df.apply(lambda row: ReducedState(row),axis=1)\n",
    "    Removedcolumns1 = df.drop(columns=[\"State\", \"fo_row_id\"])\n",
    "    RnmStateClmn = Removedcolumns1.rename(\n",
    "    columns={\n",
    "        \"ReducedState\": \"State\"\n",
    "    })\n",
    "    Sortedrows = RnmStateClmn.sort_values(by=[\"EVENT_ROW_ID\"])\n",
    "    index =  range(0,len(Sortedrows))\n",
    "    Sortedrows[\"Index\"] = index\n",
    "    State_DOWN_Remove = Sortedrows.drop(columns=[\"Datim\", \"Index\", \"EVENT_ROW_ID\"]).rename(\n",
    "    columns={\n",
    "        \"State\": \"ReducedState_DOWN\"\n",
    "    })\n",
    "    Sortedrows[\"ReducedState_DOWN\"] = Sortedrows[\"State\"].shift(1)\n",
    "    Sortedrows[\"Repeated\"] = np.where(Sortedrows[\"ReducedState_DOWN\"] == Sortedrows[\"State\"],True,False)\n",
    "    Repeated_State = Sortedrows.copy()\n",
    "    NoRepeats = Repeated_State[Repeated_State[\"Repeated\"] == False]\n",
    "    RemoveTmpClmns = NoRepeats.drop(columns=[\"Index\", \"ReducedState_DOWN\", \"Repeated\"])\n",
    "\n",
    "    if RemoveTmpClmns.shape[0] == 0:\n",
    "        Sortedrows[\"fo_row_id\"] = fo_row_id\n",
    "        return Sortedrows[[\"fo_row_id\",\"Datim\",\"EVENT_ROW_ID\",\"State\"]].iloc[0:1]\n",
    "    else:\n",
    "        RemoveTmpClmns[\"fo_row_id\"] = fo_row_id\n",
    "        return RemoveTmpClmns\n",
    "\n",
    "\n",
    "def RemoveRepeats(df):\n",
    "    RC = df.drop(columns=[\"ENT_NAME\",\"FACILITY\"])\n",
    "    sorted_rows = RC.sort_values([\"EVENT_ROW_ID\"])\n",
    "    index = range(0,len(sorted_rows))\n",
    "    sorted_rows[\"Index\"] = index\n",
    "    State_UP_Add_Index = sorted_rows.copy()\n",
    "    State_UP_Add_Index[\"Datim_UP\"] = State_UP_Add_Index[\"Datim\"].shift(-1)\n",
    "    State_UP_Add_Index[\"Datim_UP\"] = pd.to_datetime(State_UP_Add_Index[\"Datim_UP\"],format=\"%m/%d/%Y %H:%M\")\n",
    "    State_UP_Add_Index[\"Datim\"] = pd.to_datetime(State_UP_Add_Index[\"Datim\"],format=\"%m/%d/%Y %H:%M\")\n",
    "    ReplacedValue = State_UP_Add_Index.copy()\n",
    "    ReplacedValue[\"Datim_UP\"] = ReplacedValue[\"Datim_UP\"].fillna(datetime.now())\n",
    "    ReplacedValue[\"Duration_hrs\"] = (ReplacedValue[\"Datim_UP\"] - ReplacedValue[\"Datim\"])/np.timedelta64(1, 'h')\n",
    "    ReplacedValue[\"Duration_mins\"] = (ReplacedValue[\"Datim_UP\"] - ReplacedValue[\"Datim\"])/np.timedelta64(1, 'm')\n",
    "    FilteredRows2 = ReplacedValue[ReplacedValue[\"Duration_mins\"] > 10]\n",
    "\n",
    "    RemovedColumns1 = FilteredRows2.drop(columns=[\"Index\", \"Datim_UP\", \"Duration_hrs\",\"Duration_mins\"])\n",
    "    Sortedrows1 = RemovedColumns1.sort_values([\"EVENT_ROW_ID\"])\n",
    "    With_DOWN_Expanded = Sortedrows1.copy()\n",
    "    With_DOWN_Expanded[\"State_DOWN\"] = With_DOWN_Expanded[\"State\"].shift(1)\n",
    "    With_DOWN_Expanded[\"Repeated\"] = np.where(With_DOWN_Expanded['State']==With_DOWN_Expanded['State_DOWN'], True, False)\n",
    "    NoRepeats = With_DOWN_Expanded[With_DOWN_Expanded[\"Repeated\"] == False]\n",
    "    RemovedColumns2 = NoRepeats.drop(columns=[\"State_DOWN\", \"Repeated\"])\n",
    "    return RemovedColumns2[[\n",
    "        \"EVENT_ROW_ID\", \n",
    "         \"Datim\", \n",
    "         \"State\"\n",
    "    ]]\n",
    "\n",
    "\n",
    "def GetClusterStates(df):\n",
    "    SC = df[df[\"ENT_NAME\"].str.startswith(\"SC\")]\n",
    "    SC_rem_clmns = SC.drop(columns=[\"FACILITY\", \"ENT_NAME\", \"LithoCluster\"])\n",
    "    SC_renamed = SC_rem_clmns.rename(columns={\n",
    "        \"State\": \"State_SC\"\n",
    "    })\n",
    "\n",
    "\n",
    "    TR = df[df[\"ENT_NAME\"].str.startswith(\"TR\")]\n",
    "    TR_rem_clmns = TR.drop(columns=[\"FACILITY\", \"ENT_NAME\", \"LithoCluster\"])\n",
    "    TR_renamed = TR_rem_clmns.rename(columns={\n",
    "        \"State\": \"State_TR\"\n",
    "    })\n",
    "    TR_renamed\n",
    "\n",
    "    CombinedQueries = pd.concat([SC_renamed,TR_renamed])\n",
    "\n",
    "    SortedRows = CombinedQueries.sort_values([\"EVENT_ROW_ID\"])\n",
    "    FilledDown = SortedRows.copy()\n",
    "    FilledDown[\"State_SC\"] = FilledDown[\"State_SC\"].fillna(method='ffill')\n",
    "    FilledDown[\"State_TR\"] = FilledDown[\"State_TR\"].fillna(method='ffill')\n",
    "    FilledDown[\"State_SC\"] = FilledDown[\"State_SC\"].fillna('DOWN')\n",
    "    FilledDown[\"State_TR\"] = FilledDown[\"State_TR\"].fillna('DOWN')\n",
    "    AddedCustom1 = FilledDown.copy()\n",
    "    AddedCustom1[\"State\"] = np.where((AddedCustom1[\"State_SC\"] == \"UP\") & (AddedCustom1[\"State_TR\"] == \"UP\"),\"UP\",\"DOWN\")\n",
    "\n",
    "    return AddedCustom1\n",
    "\n",
    "def Tools_states_material_suppliers():\n",
    "    Expanded_Tools_parents = tool_states_result.merge(\n",
    "        Tools_Parents, \n",
    "        how='inner',\n",
    "        left_on = [\"fo_row_id\"],\n",
    "        right_on = [\"ROW_ID\"],\n",
    "        indicator=True\n",
    "    )\n",
    "\n",
    "    \n",
    "    Filtered_rows = Expanded_Tools_parents[\n",
    "        (Expanded_Tools_parents[\"ENT_NAME\"].notnull())\n",
    "        & (Expanded_Tools_parents[\"ENT_NAME\"] != \"\")\n",
    "    ]\n",
    "    Filtered_rows[\"State\"] = Filtered_rows.apply(lambda row: replaceStateValueSPC(row),axis=1)\n",
    "    Filtered_rows[\"State\"] = Filtered_rows.apply(lambda row: replaceStateValueOCAP(row),axis=1)\n",
    "\n",
    "    Removed_Columns = Filtered_rows.drop(columns=[\n",
    "        \"Area\", \n",
    "        \"fo_row_id\",\n",
    "        \"_merge\",\n",
    "        \"ROW_ID\"\n",
    "    ])\n",
    "    #Removed_Columns = Removed_Columns[Removed_Columns[\"ENT_NAME\"].isin(['TR3400'])]\n",
    "    GroupedRows = pd.DataFrame(columns=[\n",
    "        \"FACILITY\",\n",
    "        \"ENT_NAME\",\n",
    "        \"EVENT_ROW_ID\", \n",
    "        \"Datim\", \n",
    "        \"State\"\n",
    "    ])\n",
    "    facilities = Removed_Columns[\"FACILITY\"].unique()\n",
    "    print(facilities)\n",
    "    for facility in facilities:\n",
    "        facilitydata = Removed_Columns[Removed_Columns[\"FACILITY\"] == facility]\n",
    "        ent_names = facilitydata[\"ENT_NAME\"].unique()\n",
    "        \n",
    "        for ent_name in ent_names:\n",
    "            data = facilitydata[facilitydata[\"ENT_NAME\"] == ent_name]\n",
    "            NoRepeats = RemoveRepeats(data)\n",
    "            NoRepeats[\"FACILITY\"] = facility\n",
    "            NoRepeats[\"ENT_NAME\"] = ent_name\n",
    "            \n",
    "            GroupedRows = pd.concat([GroupedRows,NoRepeats])\n",
    "    \n",
    "    LithoClusters[\"LithoCluster\"] = LithoClusters[\"LithoCluster\"].map(str)\n",
    "    MergedQueries = pd.merge(\n",
    "            GroupedRows, \n",
    "            LithoClusters, \n",
    "            left_on=[\"ENT_NAME\"], \n",
    "            right_on=[\"ToolName\"], \n",
    "            how=\"left\",\n",
    "            suffixes=[\"\",\"_y\"]\n",
    "        )\n",
    "    \n",
    "    MergedQueries = MergedQueries.drop(columns = ['ToolName'])\n",
    "\n",
    "    ClusterStates = MergedQueries[(MergedQueries[\"LithoCluster\"].notnull()) & (MergedQueries[\"LithoCluster\"] != \"\")]\n",
    "\n",
    "\n",
    "\n",
    "    GrClusterStates = pd.DataFrame(columns=[\n",
    "        'EVENT_ROW_ID', \n",
    "        'Datim', \n",
    "        'State_SC', \n",
    "        'State_TR', \n",
    "        'State',\n",
    "        'FACILITY',\n",
    "        'LithoCluster'\n",
    "        \n",
    "    ])\n",
    "    \n",
    "    facilities = ClusterStates[\"FACILITY\"].unique()\n",
    "\n",
    "    for facility in facilities:\n",
    "        facilitydata = ClusterStates[ClusterStates[\"FACILITY\"] == facility]\n",
    "        Litho_Clusters = facilitydata[\"LithoCluster\"].unique()\n",
    "        \n",
    "        for LithoCluster in Litho_Clusters:\n",
    "            data = facilitydata[facilitydata[\"LithoCluster\"] == LithoCluster]\n",
    "            ClusterStatesData = GetClusterStates(data)\n",
    "            ClusterStatesData[\"FACILITY\"] = facility\n",
    "            ClusterStatesData[\"LithoCluster\"] = LithoCluster\n",
    "            \n",
    "            GrClusterStates = pd.concat([GrClusterStates,ClusterStatesData])\n",
    "            print(facility,LithoCluster)\n",
    "            \n",
    "    \n",
    "    GrExpand = GrClusterStates.copy()\n",
    "    GrExpand[\"LithoCluster\"] = GrExpand[\"LithoCluster\"].map(str)\n",
    "\n",
    "    GrExpand[\"LithoCluster\"] = [\"LithoCluster_\" + str(x) for x in GrExpand[\"LithoCluster\"]]\n",
    "\n",
    "    GrReplace = GrExpand.copy()\n",
    "    GrRename = GrReplace.rename(columns={\n",
    "        \"LithoCluster\":\"ENT_NAME\"\n",
    "    })\n",
    "    TrStates = GrRename.copy()\n",
    "    TrStates[\"ENT_NAME\"] = TrStates[\"ENT_NAME\"].str.replace(\"LithoCluster_\",\"TR\")\n",
    "    TrStates[\"State\"] = TrStates[\"State_TR\"]\n",
    "    NonClusters = MergedQueries[MergedQueries[\"LithoCluster\"].isnull()]\n",
    "    NonClustersRC = NonClusters.drop(columns=[\"LithoCluster\"])\n",
    "    Combined = pd.concat([NonClustersRC, GrRename, TrStates])\n",
    "    Combined = Combined.rename(columns={\"ENT_NAME\": \"Tool\"})\n",
    "    return Combined\n",
    "        \n",
    "\n",
    "\n",
    "def replaceStateValueSPC(row):\n",
    "    if (\"ILIME\" in row[\"Area\"]) or (row[\"ENT_NAME\"] in AllTracks):\n",
    "        return row[\"State\"].replace(\"SPC\",\"UP\")\n",
    "    return  row[\"State\"].replace(\"SPC\",\"DOWN\")\n",
    "\n",
    "def replaceStateValueOCAP(row):\n",
    "    if (row[\"ENT_NAME\"] in AllTracks):\n",
    "        return row[\"State\"].replace(\"OCAP\",\"UP\")\n",
    "    return  row[\"State\"].replace(\"OCAP\",\"DOWN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "aef870f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MergedQueries (2835, 14)\n",
      "['PLINE300' 'PLINE200']\n",
      "PLINE300 1950\n",
      "PLINE300 3300\n",
      "PLINE300 2000\n",
      "PLINE300 1000\n",
      "PLINE300 3400\n",
      "(3143, 7)\n"
     ]
    }
   ],
   "source": [
    "#Start of execution\n",
    "folder = \"C:\\\\Users\\\\fpicaso\\\\Repos\\\\PMOPS\\\\20230130\\\\\"\n",
    "Fab300_Raw = pd.read_csv(folder + \"Fab300 Raw Reservations.csv\")\n",
    "\n",
    "#format the date\n",
    "Fab300_Raw[\"DATE_TIME_STAMP\"] = pd.to_datetime(Fab300_Raw[\"DATE_TIME_STAMP\"],format=\"%d/%m/%Y %H:%M\")\n",
    "Tools_with_reservations = processFab300RawReservations(Fab300_Raw)\n",
    "\n",
    "Tools_Parents = pd.read_csv(folder + \"Tools_Parents.csv\")\n",
    "Tools_Parents[\"CSIM_TIMESTAMP\"] = pd.to_datetime(Tools_Parents[\"CSIM_TIMESTAMP\"])\n",
    "\n",
    "df_FAB300_with_tool_names = FAB300_with_tool_names(Tools_with_reservations,Tools_Parents)\n",
    "#df_FAB300_with_tool_names = pd.read_csv(folder + \"7. Fab300 with tool names.csv\")\n",
    "            \n",
    "\n",
    "IIO_raw = pd.read_csv(folder + \"4. IIO_raw_reservations .csv\")\n",
    "\n",
    "#format the date\n",
    "IIO_raw[\"Begin\"] = pd.to_datetime(IIO_raw[\"Begin\"],format=\"%Y-%m-%d %H:%M\")\n",
    "IIO_raw[\"End\"] = pd.to_datetime(IIO_raw[\"End\"],format=\"%Y-%m-%d %H:%M\")\n",
    "    \n",
    "df_IIO_without_modules = IIO_without_modules(IIO_raw)\n",
    "\n",
    "#df_IIO_without_modules = pd.read_csv(folder + \"8. IIO_without_modules.csv\")\n",
    "\n",
    "\n",
    "#Fab300_IIO_overlaps_ids\n",
    "Source_fab = df_FAB300_with_tool_names.copy()\n",
    "RC_fab = Source_fab.drop(columns=[\"ResTk\", \"User_id\"])\n",
    "UnPivot_fab = pd.melt(RC_fab, id_vars=[\"WBS\", \"FACILITY\", \"Tool\", \"Fab300_Res_id\"], \n",
    "                value_vars=[\"Begin\", \"End\"])\n",
    "UnPivot_fab = UnPivot_fab.rename(\n",
    "columns={\n",
    "    \"variable\": \"FAB300_BeginEnd\",\n",
    "    \"value\": \"DateTime\"\n",
    "})\n",
    "UnPivot_fab[\"FAB_IIO_Flag\"] = \"FAB\"\n",
    "\n",
    "Source_iio = df_IIO_without_modules.copy()\n",
    "RC_iio = Source_iio.drop(columns=[\"Modules\", \"User_id\", \"Description\"])\n",
    "UnPivot_iio = pd.melt(RC_iio, id_vars=[\"WBS\", \"FACILITY\", \"Tool\", \"IIO_Res_id\"], \n",
    "                value_vars=[\"Begin\", \"End\"])\n",
    "\n",
    "UnPivot_iio = UnPivot_iio.rename(\n",
    "columns={\n",
    "    \"variable\": \"IIO_BeginEnd\",\n",
    "    \"value\": \"DateTime\"\n",
    "})\n",
    "UnPivot_iio[\"FAB_IIO_Flag\"] = \"IIO\"\n",
    "\n",
    "fab_iio_together  = pd.concat([UnPivot_fab, UnPivot_iio], ignore_index=True)\n",
    "\n",
    "columns = [\n",
    "    'FAB_IIO_Flag',\n",
    "    'Fab300_Res_id', \n",
    "    'IIO_Res_id', \n",
    "    'Cluster', \n",
    "    'Fab300_Begin', \n",
    "    'Fab300_End',\n",
    "    'FACILITY', \n",
    "    'ResTk', \n",
    "    'Tool', \n",
    "    'Fab300_User_id', \n",
    "    'WBS', \n",
    "    'IIO_Begin',\n",
    "    'Description', \n",
    "    'IIO_End'\n",
    "]\n",
    "\n",
    "Fab300_IIO_overlaps_ids = pd.DataFrame(columns = columns)\n",
    "\n",
    "WBSs = fab_iio_together[\"WBS\"].unique()\n",
    "\n",
    "for wbs in WBSs:\n",
    "    wbsdata = fab_iio_together[\n",
    "        (fab_iio_together[\"WBS\"] == wbs)\n",
    "    ]\n",
    "    facilities = wbsdata[\"FACILITY\"].unique()\n",
    "    for facility in facilities:\n",
    "        facilityData = wbsdata[\n",
    "            (wbsdata[\"FACILITY\"] == facility)\n",
    "        ]\n",
    "        tools = facilityData[\"Tool\"].unique()\n",
    "        for tool in tools:\n",
    "            wbstooldata = facilityData[\n",
    "                (wbsdata[\"Tool\"] == tool)\n",
    "            ]\n",
    "            df = Fab300_iio_merger(wbstooldata)\n",
    "            Fab300_IIO_overlaps_ids = pd.concat([Fab300_IIO_overlaps_ids,df])\n",
    "            \n",
    "\n",
    "\n",
    "#Final_Fab300_IIO_reservations\n",
    "\n",
    "Final_Fab300_IIO_reservations_df = Final_Fab300_IIO_reservations(df_IIO_without_modules,df_FAB300_with_tool_names,Fab300_IIO_overlaps_ids)\n",
    "\n",
    "\n",
    "#Step 14\n",
    "Final_Fab300_IIO_reservations_df[\"Begin\"] = pd.to_datetime(Final_Fab300_IIO_reservations_df[\"Begin\"],format=\"%Y-%m-%d %H:%M\")\n",
    "Final_Fab300_IIO_reservations_df[\"End\"] = pd.to_datetime(Final_Fab300_IIO_reservations_df[\"End\"],format=\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "\n",
    "LithoClusters = pd.read_csv(folder + \"13. LithoClusters.csv\")\n",
    "\n",
    "Final_Fab300_IIO_Reservations_clustered_df = Final_Fab300_IIO_Reservations_clustered(Final_Fab300_IIO_reservations_df)\n",
    "\n",
    "#Tool States and Transform States\n",
    "\n",
    "\n",
    "#Tool States and Transform States\n",
    "\n",
    "tool_states = pd.read_csv(folder + \"Tool_States.csv\")\n",
    "tool_states[\"Datim\"] = pd.to_datetime(tool_states[\"Datim\"],format=\"%d/%m/%Y %H:%M\")\n",
    "\n",
    "fo_row_ids = tool_states[\"fo_row_id\"].unique()\n",
    "\n",
    "tool_states_result = pd.DataFrame(\n",
    "columns=[\n",
    "    \"Datim\",\n",
    "    \"EVENT_ROW_ID\",\n",
    "    \"State\"\n",
    "])\n",
    "\n",
    "for fo_row_id in fo_row_ids:\n",
    "    df = tool_states[tool_states[\"fo_row_id\"] == fo_row_id]\n",
    "    tool_states_df = Transform_states(df,fo_row_id)\n",
    "    tool_states_result = pd.concat([tool_states_result,tool_states_df])\n",
    "\n",
    "\n",
    "\n",
    "#17. Tools_states_material_suppliers\n",
    "AllTracks = [\"TR1000\", \"TR1950\", \"TR1970\", \"TR2000\", \"TR3300\", \"TR3400\", \"TRDSA\", \"TRMTM\", \"TRDUOS\"]\n",
    "\n",
    "Tools_states_material_suppliers_df = Tools_states_material_suppliers()\n",
    "print(Tools_states_material_suppliers_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b731a5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2651, 15)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Fab300_IIO_Reservations_clustered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68e8b9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Tool States and Transform States\n",
    "\n",
    "tool_states = pd.read_csv(folder + \"Tool_States.csv\")\n",
    "tool_states[\"Datim\"] = pd.to_datetime(tool_states[\"Datim\"],format=\"%d/%m/%Y %H:%M\")\n",
    "\n",
    "fo_row_ids = tool_states[\"fo_row_id\"].unique()\n",
    "\n",
    "tool_states_result = pd.DataFrame(\n",
    "columns=[\n",
    "    \"Datim\",\n",
    "    \"EVENT_ROW_ID\",\n",
    "    \"State\"\n",
    "])\n",
    "\n",
    "for fo_row_id in fo_row_ids:\n",
    "    df = tool_states[tool_states[\"fo_row_id\"] == fo_row_id]\n",
    "    tool_states_df = Transform_states(df,fo_row_id)\n",
    "    tool_states_result = pd.concat([tool_states_result,tool_states_df])\n",
    "\n",
    "\n",
    "\n",
    "#17. Tools_states_material_suppliers\n",
    "AllTracks = [\"TR1000\", \"TR1950\", \"TR1970\", \"TR2000\", \"TR3300\", \"TR3400\", \"TRDSA\", \"TRMTM\", \"TRDUOS\"]\n",
    "\n",
    "#Tools_states_material_suppliers_df = Tools_states_material_suppliers()\n",
    "\n",
    "#Tools_states_material_suppliers_df.to_csv(folder + \"Tools_states_material_suppliers_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "82ea6f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11915, 4)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_states_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "edd14f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PLINE300' 'PLINE200']\n",
      "PLINE300 1950\n",
      "PLINE300 3300\n",
      "PLINE300 2000\n",
      "PLINE300 1000\n",
      "PLINE300 3400\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    Expanded_Tools_parents = tool_states_result.merge(\n",
    "        Tools_Parents, \n",
    "        how='inner',\n",
    "        left_on = [\"fo_row_id\"],\n",
    "        right_on = [\"ROW_ID\"],\n",
    "        indicator=True\n",
    "    )\n",
    "\n",
    "    \n",
    "    Filtered_rows = Expanded_Tools_parents[\n",
    "        (Expanded_Tools_parents[\"ENT_NAME\"].notnull())\n",
    "        & (Expanded_Tools_parents[\"ENT_NAME\"] != \"\")\n",
    "    ]\n",
    "    Filtered_rows[\"State\"] = Filtered_rows.apply(lambda row: replaceStateValueSPC(row),axis=1)\n",
    "    Filtered_rows[\"State\"] = Filtered_rows.apply(lambda row: replaceStateValueOCAP(row),axis=1)\n",
    "\n",
    "    Removed_Columns = Filtered_rows.drop(columns=[\n",
    "        \"Area\", \n",
    "        \"fo_row_id\",\n",
    "        \"_merge\",\n",
    "        \"ROW_ID\"\n",
    "    ])\n",
    "    #Removed_Columns = Removed_Columns[Removed_Columns[\"ENT_NAME\"].isin(['TR3400'])]\n",
    "    GroupedRows = pd.DataFrame(columns=[\n",
    "        \"FACILITY\",\n",
    "        \"ENT_NAME\",\n",
    "        \"EVENT_ROW_ID\", \n",
    "        \"Datim\", \n",
    "        \"State\"\n",
    "    ])\n",
    "    facilities = Removed_Columns[\"FACILITY\"].unique()\n",
    "    print(facilities)\n",
    "    for facility in facilities:\n",
    "        facilitydata = Removed_Columns[Removed_Columns[\"FACILITY\"] == facility]\n",
    "        ent_names = facilitydata[\"ENT_NAME\"].unique()\n",
    "        \n",
    "        for ent_name in ent_names:\n",
    "            data = facilitydata[facilitydata[\"ENT_NAME\"] == ent_name]\n",
    "            NoRepeats = RemoveRepeats(data)\n",
    "            NoRepeats[\"FACILITY\"] = facility\n",
    "            NoRepeats[\"ENT_NAME\"] = ent_name\n",
    "            \n",
    "            GroupedRows = pd.concat([GroupedRows,NoRepeats])\n",
    "    \n",
    "    LithoClusters[\"LithoCluster\"] = LithoClusters[\"LithoCluster\"].map(str)\n",
    "    MergedQueries = pd.merge(\n",
    "            GroupedRows, \n",
    "            LithoClusters, \n",
    "            left_on=[\"ENT_NAME\"], \n",
    "            right_on=[\"ToolName\"], \n",
    "            how=\"left\",\n",
    "            suffixes=[\"\",\"_y\"]\n",
    "        )\n",
    "    \n",
    "    MergedQueries = MergedQueries.drop(columns = ['ToolName'])\n",
    "\n",
    "    ClusterStates = MergedQueries[(MergedQueries[\"LithoCluster\"].notnull()) & (MergedQueries[\"LithoCluster\"] != \"\")]\n",
    "\n",
    "\n",
    "\n",
    "    GrClusterStates = pd.DataFrame(columns=[\n",
    "        'EVENT_ROW_ID', \n",
    "        'Datim', \n",
    "        'State_SC', \n",
    "        'State_TR', \n",
    "        'State',\n",
    "        'FACILITY',\n",
    "        'LithoCluster'\n",
    "        \n",
    "    ])\n",
    "    \n",
    "    facilities = ClusterStates[\"FACILITY\"].unique()\n",
    "\n",
    "    for facility in facilities:\n",
    "        facilitydata = ClusterStates[ClusterStates[\"FACILITY\"] == facility]\n",
    "        Litho_Clusters = facilitydata[\"LithoCluster\"].unique()\n",
    "        \n",
    "        for LithoCluster in Litho_Clusters:\n",
    "            data = facilitydata[facilitydata[\"LithoCluster\"] == LithoCluster]\n",
    "            ClusterStatesData = GetClusterStates(data)\n",
    "            ClusterStatesData[\"FACILITY\"] = facility\n",
    "            ClusterStatesData[\"LithoCluster\"] = LithoCluster\n",
    "            \n",
    "            GrClusterStates = pd.concat([GrClusterStates,ClusterStatesData])\n",
    "            print(facility,LithoCluster)\n",
    "            \n",
    "    GrExpand[\"LithoCluster\"] = GrExpand[\"LithoCluster\"].map(str)\n",
    "\n",
    "    GrExpand = GrClusterStates.copy()\n",
    "    GrExpand[\"LithoCluster\"] = [\"LithoCluster_\" + str(x) for x in GrExpand[\"LithoCluster\"]]\n",
    "\n",
    "    GrReplace = GrExpand.copy()\n",
    "    GrRename = GrReplace.rename(columns={\n",
    "        \"LithoCluster\":\"ENT_NAME\"\n",
    "    })\n",
    "    TrStates = GrRename.copy()\n",
    "    TrStates[\"ENT_NAME\"] = TrStates[\"ENT_NAME\"].str.replace(\"LithoCluster_\",\"TR\")\n",
    "    TrStates[\"State\"] = TrStates[\"State_TR\"]\n",
    "    NonClusters = MergedQueries[MergedQueries[\"LithoCluster\"].isnull()]\n",
    "    NonClustersRC = NonClusters.drop(columns=[\"LithoCluster\"])\n",
    "    Combined = pd.concat([NonClustersRC, GrRename, TrStates])\n",
    "    Combined = Combined.rename(columns={\"ENT_NAME\": \"Tool\"})\n",
    "    Combined.to_csv(\"Combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f3f54837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EVENT_ROW_ID</th>\n",
       "      <th>Datim</th>\n",
       "      <th>State_SC</th>\n",
       "      <th>State_TR</th>\n",
       "      <th>State</th>\n",
       "      <th>FACILITY</th>\n",
       "      <th>ENT_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>959604449</td>\n",
       "      <td>2023-01-02 08:30:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>959832894</td>\n",
       "      <td>2023-01-03 04:35:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>959867956</td>\n",
       "      <td>2023-01-03 08:28:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>959875319</td>\n",
       "      <td>2023-01-03 09:36:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>960972770</td>\n",
       "      <td>2023-01-06 23:44:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>960990545</td>\n",
       "      <td>2023-01-07 03:33:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>961234941</td>\n",
       "      <td>2023-01-08 21:30:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>961244433</td>\n",
       "      <td>2023-01-08 23:59:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>961891126</td>\n",
       "      <td>2023-01-11 05:01:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>961894393</td>\n",
       "      <td>2023-01-11 05:32:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>961923524</td>\n",
       "      <td>2023-01-11 08:23:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>962154423</td>\n",
       "      <td>2023-01-11 21:58:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>962206534</td>\n",
       "      <td>2023-01-12 03:04:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>962211038</td>\n",
       "      <td>2023-01-12 03:31:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>962251646</td>\n",
       "      <td>2023-01-12 08:44:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>962620772</td>\n",
       "      <td>2023-01-13 11:11:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>962826124</td>\n",
       "      <td>2023-01-13 23:26:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>962863775</td>\n",
       "      <td>2023-01-14 03:46:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>962959136</td>\n",
       "      <td>2023-01-14 15:23:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>963015495</td>\n",
       "      <td>2023-01-14 19:00:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>963047526</td>\n",
       "      <td>2023-01-14 23:46:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>963062342</td>\n",
       "      <td>2023-01-15 02:36:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>963213003</td>\n",
       "      <td>2023-01-15 21:30:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>963221693</td>\n",
       "      <td>2023-01-15 23:33:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>964188002</td>\n",
       "      <td>2023-01-18 21:30:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>964212810</td>\n",
       "      <td>2023-01-18 23:22:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>964216757</td>\n",
       "      <td>2023-01-18 23:37:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>964322806</td>\n",
       "      <td>2023-01-19 10:11:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>964528437</td>\n",
       "      <td>2023-01-19 20:41:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>964545422</td>\n",
       "      <td>2023-01-19 21:37:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>965180588</td>\n",
       "      <td>2023-01-22 04:17:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>965223321</td>\n",
       "      <td>2023-01-22 10:46:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>965311583</td>\n",
       "      <td>2023-01-22 21:30:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>965321875</td>\n",
       "      <td>2023-01-22 23:09:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>965334652</td>\n",
       "      <td>2023-01-23 02:34:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>965341650</td>\n",
       "      <td>2023-01-23 04:49:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>965363639</td>\n",
       "      <td>2023-01-23 08:03:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>965374489</td>\n",
       "      <td>2023-01-23 09:07:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>965417125</td>\n",
       "      <td>2023-01-23 11:33:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>965440297</td>\n",
       "      <td>2023-01-23 13:16:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>965445542</td>\n",
       "      <td>2023-01-23 13:35:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>965454250</td>\n",
       "      <td>2023-01-23 13:56:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>965845196</td>\n",
       "      <td>2023-01-24 16:07:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>965927786</td>\n",
       "      <td>2023-01-24 21:58:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>966029609</td>\n",
       "      <td>2023-01-25 07:54:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>966038155</td>\n",
       "      <td>2023-01-25 08:56:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>966154536</td>\n",
       "      <td>2023-01-25 15:59:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>966167242</td>\n",
       "      <td>2023-01-25 16:44:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>UP</td>\n",
       "      <td>UP</td>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR3400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EVENT_ROW_ID               Datim State_SC State_TR State  FACILITY ENT_NAME\n",
       "0     959604449 2023-01-02 08:30:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "1     959832894 2023-01-03 04:35:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "2     959867956 2023-01-03 08:28:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "3     959875319 2023-01-03 09:36:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "4     960972770 2023-01-06 23:44:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "5     960990545 2023-01-07 03:33:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "6     961234941 2023-01-08 21:30:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "7     961244433 2023-01-08 23:59:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "8     961891126 2023-01-11 05:01:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "9     961894393 2023-01-11 05:32:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "10    961923524 2023-01-11 08:23:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "11    962154423 2023-01-11 21:58:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "12    962206534 2023-01-12 03:04:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "13    962211038 2023-01-12 03:31:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "14    962251646 2023-01-12 08:44:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "15    962620772 2023-01-13 11:11:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "16    962826124 2023-01-13 23:26:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "17    962863775 2023-01-14 03:46:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "18    962959136 2023-01-14 15:23:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "19    963015495 2023-01-14 19:00:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "20    963047526 2023-01-14 23:46:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "21    963062342 2023-01-15 02:36:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "22    963213003 2023-01-15 21:30:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "23    963221693 2023-01-15 23:33:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "24    964188002 2023-01-18 21:30:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "25    964212810 2023-01-18 23:22:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "26    964216757 2023-01-18 23:37:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "27    964322806 2023-01-19 10:11:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "28    964528437 2023-01-19 20:41:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "29    964545422 2023-01-19 21:37:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "30    965180588 2023-01-22 04:17:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "31    965223321 2023-01-22 10:46:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "32    965311583 2023-01-22 21:30:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "33    965321875 2023-01-22 23:09:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "34    965334652 2023-01-23 02:34:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "35    965341650 2023-01-23 04:49:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "36    965363639 2023-01-23 08:03:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "37    965374489 2023-01-23 09:07:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "38    965417125 2023-01-23 11:33:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "39    965440297 2023-01-23 13:16:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "40    965445542 2023-01-23 13:35:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "41    965454250 2023-01-23 13:56:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "42    965845196 2023-01-24 16:07:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "43    965927786 2023-01-24 21:58:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "44    966029609 2023-01-25 07:54:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "45    966038155 2023-01-25 08:56:00     DOWN       UP    UP  PLINE300   TR3400\n",
       "46    966154536 2023-01-25 15:59:00     DOWN     DOWN  DOWN  PLINE300   TR3400\n",
       "47    966167242 2023-01-25 16:44:00     DOWN       UP    UP  PLINE300   TR3400"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrStates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7b8a38e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LithoCluster_3400'], dtype=object)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Combined[Combined[\"Tool\"].str.contains('3400')].Tool.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ccd19bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FACILITY</th>\n",
       "      <th>ENT_NAME</th>\n",
       "      <th>EVENT_ROW_ID</th>\n",
       "      <th>Datim</th>\n",
       "      <th>State</th>\n",
       "      <th>LithoCluster</th>\n",
       "      <th>ToolName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR1950</td>\n",
       "      <td>959602003</td>\n",
       "      <td>2023-01-02 08:16:02</td>\n",
       "      <td>UP</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>TR1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR1950</td>\n",
       "      <td>959953684</td>\n",
       "      <td>2023-01-03 13:17:25</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>TR1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR1950</td>\n",
       "      <td>959960788</td>\n",
       "      <td>2023-01-03 13:49:21</td>\n",
       "      <td>UP</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>TR1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR1950</td>\n",
       "      <td>961487298</td>\n",
       "      <td>2023-01-09 19:06:35</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>TR1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>PLINE300</td>\n",
       "      <td>TR1950</td>\n",
       "      <td>961506292</td>\n",
       "      <td>2023-01-09 19:37:24</td>\n",
       "      <td>UP</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>TR1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>PLINE300</td>\n",
       "      <td>SC2000</td>\n",
       "      <td>959603492</td>\n",
       "      <td>2023-01-02 08:25:31</td>\n",
       "      <td>UP</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>SC2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>PLINE300</td>\n",
       "      <td>SC2000</td>\n",
       "      <td>959612910</td>\n",
       "      <td>2023-01-02 09:52:23</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>SC2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>PLINE300</td>\n",
       "      <td>SC2000</td>\n",
       "      <td>959869826</td>\n",
       "      <td>2023-01-03 09:02:27</td>\n",
       "      <td>UP</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>SC2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>PLINE300</td>\n",
       "      <td>SC2000</td>\n",
       "      <td>964721246</td>\n",
       "      <td>2023-01-20 12:08:54</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>SC2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>PLINE300</td>\n",
       "      <td>SC2000</td>\n",
       "      <td>964784832</td>\n",
       "      <td>2023-01-20 15:06:14</td>\n",
       "      <td>UP</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>SC2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FACILITY ENT_NAME EVENT_ROW_ID               Datim State  LithoCluster  \\\n",
       "481   PLINE300   TR1950    959602003 2023-01-02 08:16:02    UP        1950.0   \n",
       "482   PLINE300   TR1950    959953684 2023-01-03 13:17:25  DOWN        1950.0   \n",
       "483   PLINE300   TR1950    959960788 2023-01-03 13:49:21    UP        1950.0   \n",
       "484   PLINE300   TR1950    961487298 2023-01-09 19:06:35  DOWN        1950.0   \n",
       "485   PLINE300   TR1950    961506292 2023-01-09 19:37:24    UP        1950.0   \n",
       "...        ...      ...          ...                 ...   ...           ...   \n",
       "1262  PLINE300   SC2000    959603492 2023-01-02 08:25:31    UP        2000.0   \n",
       "1263  PLINE300   SC2000    959612910 2023-01-02 09:52:23  DOWN        2000.0   \n",
       "1264  PLINE300   SC2000    959869826 2023-01-03 09:02:27    UP        2000.0   \n",
       "1265  PLINE300   SC2000    964721246 2023-01-20 12:08:54  DOWN        2000.0   \n",
       "1266  PLINE300   SC2000    964784832 2023-01-20 15:06:14    UP        2000.0   \n",
       "\n",
       "     ToolName  \n",
       "481    TR1950  \n",
       "482    TR1950  \n",
       "483    TR1950  \n",
       "484    TR1950  \n",
       "485    TR1950  \n",
       "...       ...  \n",
       "1262   SC2000  \n",
       "1263   SC2000  \n",
       "1264   SC2000  \n",
       "1265   SC2000  \n",
       "1266   SC2000  \n",
       "\n",
       "[97 rows x 7 columns]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MergedQueries[MergedQueries[\"ToolName\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "6a77cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MergedQueries[MergedQueries[\"LithoCluster\"]==1000].to_csv(\"ForCheck.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22237dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    df = Removed_Columns.copy()\n",
    "    RC = df.drop(columns=[\"ENT_NAME\",\"FACILITY\"])\n",
    "    sorted_rows = RC.sort_values([\"EVENT_ROW_ID\"])\n",
    "    \n",
    "    index = range(0,len(sorted_rows))\n",
    "    sorted_rows[\"Index\"] = index\n",
    "    State_UP_Add_Index = sorted_rows.copy()\n",
    "    State_UP_Add_Index[\"Datim_UP\"] = State_UP_Add_Index[\"Datim\"].shift(-1)\n",
    "    State_UP_Add_Index[\"Datim_UP\"] = pd.to_datetime(State_UP_Add_Index[\"Datim_UP\"],format=\"%m/%d/%Y %H:%M\")\n",
    "    State_UP_Add_Index[\"Datim\"] = pd.to_datetime(State_UP_Add_Index[\"Datim\"],format=\"%m/%d/%Y %H:%M\")\n",
    "    ReplacedValue = State_UP_Add_Index.copy()\n",
    "    \n",
    "    ReplacedValue[\"Datim_UP\"] = ReplacedValue[\"Datim_UP\"].fillna(datetime.now())\n",
    "    ReplacedValue[\"Duration_hrs\"] = (ReplacedValue[\"Datim_UP\"] - ReplacedValue[\"Datim\"])/np.timedelta64(1, 'h')\n",
    "    ReplacedValue[\"Duration_mins\"] = (ReplacedValue[\"Datim_UP\"] - ReplacedValue[\"Datim\"])/np.timedelta64(1, 'm')\n",
    "    FilteredRows2 = ReplacedValue[ReplacedValue[\"Duration_mins\"] > 10]\n",
    "\n",
    "    RemovedColumns1 = FilteredRows2.drop(columns=[\"Index\", \"Datim_UP\", \"Duration_hrs\",\"Duration_mins\"])\n",
    "    \n",
    "    Sortedrows1 = RemovedColumns1.sort_values([\"EVENT_ROW_ID\"])\n",
    "    With_DOWN_Expanded = Sortedrows1.copy()\n",
    "    With_DOWN_Expanded[\"State_DOWN\"] = With_DOWN_Expanded[\"State\"].shift(1)\n",
    "    With_DOWN_Expanded[\"Repeated\"] = np.where(With_DOWN_Expanded['State']==With_DOWN_Expanded['State_DOWN'], True, False)\n",
    "    NoRepeats = With_DOWN_Expanded[With_DOWN_Expanded[\"Repeated\"] == False]\n",
    "    RemovedColumns2 = NoRepeats.drop(columns=[\"State_DOWN\", \"Repeated\"])\n",
    "    RemovedColumns2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7d61869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EVENT_ROW_ID</th>\n",
       "      <th>Datim</th>\n",
       "      <th>State</th>\n",
       "      <th>Index</th>\n",
       "      <th>ReducedState_DOWN</th>\n",
       "      <th>Repeated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>959680248</td>\n",
       "      <td>2023-01-02 14:01:00</td>\n",
       "      <td>UP</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>959858142</td>\n",
       "      <td>2023-01-03 07:18:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>1</td>\n",
       "      <td>UP</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>959861043</td>\n",
       "      <td>2023-01-03 07:34:00</td>\n",
       "      <td>UP</td>\n",
       "      <td>2</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>960139172</td>\n",
       "      <td>2023-01-04 06:45:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>3</td>\n",
       "      <td>UP</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>960146088</td>\n",
       "      <td>2023-01-04 07:22:00</td>\n",
       "      <td>UP</td>\n",
       "      <td>4</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>960395190</td>\n",
       "      <td>2023-01-05 06:36:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>5</td>\n",
       "      <td>UP</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>960398044</td>\n",
       "      <td>2023-01-05 06:51:00</td>\n",
       "      <td>UP</td>\n",
       "      <td>6</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>960703683</td>\n",
       "      <td>2023-01-06 06:48:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>7</td>\n",
       "      <td>UP</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>960706658</td>\n",
       "      <td>2023-01-06 07:06:00</td>\n",
       "      <td>UP</td>\n",
       "      <td>8</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>961177872</td>\n",
       "      <td>2023-01-08 12:00:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>9</td>\n",
       "      <td>UP</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>961234762</td>\n",
       "      <td>2023-01-08 21:23:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>10</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>961234769</td>\n",
       "      <td>2023-01-08 21:24:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>11</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>961235238</td>\n",
       "      <td>2023-01-08 21:37:00</td>\n",
       "      <td>UP</td>\n",
       "      <td>12</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>961748025</td>\n",
       "      <td>2023-01-10 17:03:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>13</td>\n",
       "      <td>UP</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>961748137</td>\n",
       "      <td>2023-01-10 17:04:00</td>\n",
       "      <td>UP</td>\n",
       "      <td>14</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>961894174</td>\n",
       "      <td>2023-01-11 05:30:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>15</td>\n",
       "      <td>UP</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>961898341</td>\n",
       "      <td>2023-01-11 06:02:00</td>\n",
       "      <td>UP</td>\n",
       "      <td>16</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>963120317</td>\n",
       "      <td>2023-01-15 12:00:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>17</td>\n",
       "      <td>UP</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>963237654</td>\n",
       "      <td>2023-01-16 03:14:00</td>\n",
       "      <td>UP</td>\n",
       "      <td>18</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>963329150</td>\n",
       "      <td>2023-01-16 10:51:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>19</td>\n",
       "      <td>UP</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>963329383</td>\n",
       "      <td>2023-01-16 10:52:00</td>\n",
       "      <td>UP</td>\n",
       "      <td>20</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>964041736</td>\n",
       "      <td>2023-01-18 13:01:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>21</td>\n",
       "      <td>UP</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>964041864</td>\n",
       "      <td>2023-01-18 13:01:00</td>\n",
       "      <td>UP</td>\n",
       "      <td>22</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>964396550</td>\n",
       "      <td>2023-01-19 13:52:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>23</td>\n",
       "      <td>UP</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>964396636</td>\n",
       "      <td>2023-01-19 13:52:00</td>\n",
       "      <td>UP</td>\n",
       "      <td>24</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>964750744</td>\n",
       "      <td>2023-01-20 13:47:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>25</td>\n",
       "      <td>UP</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>964750883</td>\n",
       "      <td>2023-01-20 13:47:00</td>\n",
       "      <td>UP</td>\n",
       "      <td>26</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>965097949</td>\n",
       "      <td>2023-01-21 17:03:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>27</td>\n",
       "      <td>UP</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>965097980</td>\n",
       "      <td>2023-01-21 17:03:00</td>\n",
       "      <td>UP</td>\n",
       "      <td>28</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>965195332</td>\n",
       "      <td>2023-01-22 07:47:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>29</td>\n",
       "      <td>UP</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>965200293</td>\n",
       "      <td>2023-01-22 08:25:00</td>\n",
       "      <td>UP</td>\n",
       "      <td>30</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>965390730</td>\n",
       "      <td>2023-01-23 10:13:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>31</td>\n",
       "      <td>UP</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>965390790</td>\n",
       "      <td>2023-01-23 10:14:00</td>\n",
       "      <td>UP</td>\n",
       "      <td>32</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>966012053</td>\n",
       "      <td>2023-01-25 06:37:00</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>33</td>\n",
       "      <td>UP</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>966012169</td>\n",
       "      <td>2023-01-25 06:37:00</td>\n",
       "      <td>UP</td>\n",
       "      <td>34</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    EVENT_ROW_ID               Datim State  Index ReducedState_DOWN  Repeated\n",
       "0      959680248 2023-01-02 14:01:00    UP      0               NaN     False\n",
       "1      959858142 2023-01-03 07:18:00  DOWN      1                UP     False\n",
       "2      959861043 2023-01-03 07:34:00    UP      2              DOWN     False\n",
       "3      960139172 2023-01-04 06:45:00  DOWN      3                UP     False\n",
       "4      960146088 2023-01-04 07:22:00    UP      4              DOWN     False\n",
       "5      960395190 2023-01-05 06:36:00  DOWN      5                UP     False\n",
       "6      960398044 2023-01-05 06:51:00    UP      6              DOWN     False\n",
       "7      960703683 2023-01-06 06:48:00  DOWN      7                UP     False\n",
       "8      960706658 2023-01-06 07:06:00    UP      8              DOWN     False\n",
       "9      961177872 2023-01-08 12:00:00  DOWN      9                UP     False\n",
       "10     961234762 2023-01-08 21:23:00  DOWN     10              DOWN      True\n",
       "11     961234769 2023-01-08 21:24:00  DOWN     11              DOWN      True\n",
       "12     961235238 2023-01-08 21:37:00    UP     12              DOWN     False\n",
       "13     961748025 2023-01-10 17:03:00  DOWN     13                UP     False\n",
       "14     961748137 2023-01-10 17:04:00    UP     14              DOWN     False\n",
       "15     961894174 2023-01-11 05:30:00  DOWN     15                UP     False\n",
       "16     961898341 2023-01-11 06:02:00    UP     16              DOWN     False\n",
       "17     963120317 2023-01-15 12:00:00  DOWN     17                UP     False\n",
       "18     963237654 2023-01-16 03:14:00    UP     18              DOWN     False\n",
       "19     963329150 2023-01-16 10:51:00  DOWN     19                UP     False\n",
       "20     963329383 2023-01-16 10:52:00    UP     20              DOWN     False\n",
       "21     964041736 2023-01-18 13:01:00  DOWN     21                UP     False\n",
       "22     964041864 2023-01-18 13:01:00    UP     22              DOWN     False\n",
       "23     964396550 2023-01-19 13:52:00  DOWN     23                UP     False\n",
       "24     964396636 2023-01-19 13:52:00    UP     24              DOWN     False\n",
       "25     964750744 2023-01-20 13:47:00  DOWN     25                UP     False\n",
       "26     964750883 2023-01-20 13:47:00    UP     26              DOWN     False\n",
       "27     965097949 2023-01-21 17:03:00  DOWN     27                UP     False\n",
       "28     965097980 2023-01-21 17:03:00    UP     28              DOWN     False\n",
       "29     965195332 2023-01-22 07:47:00  DOWN     29                UP     False\n",
       "30     965200293 2023-01-22 08:25:00    UP     30              DOWN     False\n",
       "31     965390730 2023-01-23 10:13:00  DOWN     31                UP     False\n",
       "32     965390790 2023-01-23 10:14:00    UP     32              DOWN     False\n",
       "33     966012053 2023-01-25 06:37:00  DOWN     33                UP     False\n",
       "34     966012169 2023-01-25 06:37:00    UP     34              DOWN     False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RC = df.drop(columns=[\"ENT_NAME\",\"FACILITY\"])\n",
    "    sorted_rows = RC.sort_values([\"EVENT_ROW_ID\"])\n",
    "    index = range(0,len(sorted_rows))\n",
    "    sorted_rows[\"Index\"] = index\n",
    "    State_UP_Add_Index = sorted_rows.copy()\n",
    "    State_UP_Add_Index[\"Datim_UP\"] = State_UP_Add_Index[\"Datim\"].shift(-1)\n",
    "    State_UP_Add_Index[\"Datim_UP\"] = pd.to_datetime(State_UP_Add_Index[\"Datim_UP\"],format=\"%m/%d/%Y %H:%M\")\n",
    "    State_UP_Add_Index[\"Datim\"] = pd.to_datetime(State_UP_Add_Index[\"Datim\"],format=\"%m/%d/%Y %H:%M\")\n",
    "    ReplacedValue = State_UP_Add_Index.copy()\n",
    "    ReplacedValue[\"Datim_UP\"] = ReplacedValue[\"Datim_UP\"].fillna(datetime.now())\n",
    "    ReplacedValue[\"Duration_hrs\"] = (ReplacedValue[\"Datim_UP\"] - ReplacedValue[\"Datim\"])/np.timedelta64(1, 'h')\n",
    "    ReplacedValue[\"Duration_mins\"] = (ReplacedValue[\"Datim_UP\"] - ReplacedValue[\"Datim\"])/np.timedelta64(1, 'm')\n",
    "    FilteredRows2 = ReplacedValue[ReplacedValue[\"Duration_mins\"] > 10]\n",
    "\n",
    "    RemovedColumns1 = FilteredRows2.drop(columns=[\"Index\", \"Datim_UP\", \"Duration_hrs\",\"Duration_mins\"])\n",
    "    Sortedrows1 = RemovedColumns1.sort_values([\"EVENT_ROW_ID\"])\n",
    "    With_DOWN_Expanded = Sortedrows1.copy()\n",
    "    With_DOWN_Expanded[\"State_DOWN\"] = With_DOWN_Expanded[\"State\"].shift(1)\n",
    "    With_DOWN_Expanded[\"Repeated\"] = np.where(With_DOWN_Expanded['State']==With_DOWN_Expanded['State_DOWN'], True, False)\n",
    "    NoRepeats = With_DOWN_Expanded[With_DOWN_Expanded[\"Repeated\"] == False]\n",
    "    RemovedColumns2 = NoRepeats.drop(columns=[\"State_DOWN\", \"Repeated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c483ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
